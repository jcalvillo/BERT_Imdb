{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from: https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb#scrollTo=hhbGEfwgdEtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Load all files from a directory in a DataFrame.\n",
    "def load_directory_data(directory):\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"sentiment\"] = []\n",
    "    for file_path in os.listdir(directory):\n",
    "        with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "            data[\"sentence\"].append(f.read())\n",
    "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "    pos_df[\"polarity\"] = 1\n",
    "    neg_df[\"polarity\"] = 0\n",
    "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Download and process the dataset files.\n",
    "def load_datasets():\n",
    "    data_dir = '/home/eugenet/final_project/data/'\n",
    "    train_df = load_dataset(os.path.join(data_dir, \"aclImdb\", \"train\"))\n",
    "    test_df = load_dataset(os.path.join(data_dir, \"aclImdb\", \"test\"))\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train[20000:25000]\n",
    "train = train[0:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'sentence'\n",
    "LABEL_COLUMN = 'polarity'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eugenet/miniconda3/envs/bert/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 00:29:12.628666 140278568785728 deprecation.py:323] From /home/eugenet/miniconda3/envs/bert/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 00:29:17.637620 140278568785728 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-24_H-1024_A-16/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return bert.tokenization.FullTokenizer(\n",
    "        vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        f1_score = tf.contrib.metrics.f1_score(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        auc = tf.metrics.auc(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        recall = tf.metrics.recall(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        precision = tf.metrics.precision(\n",
    "            label_ids,\n",
    "            predicted_labels) \n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"auc\": auc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg\n",
    "        }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.386735 140278568785728 run_classifier.py:774] Writing example 0 of 20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.399857 140278568785728 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.402209 140278568785728 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i would have enjoyed this movie slightly more had not been for jason ( herb ) ever ##s constant harp ##ing on experiment . many early reviewers of the seven samurai accused to ##shi ##ro mi ##fu ##ne of over ##act ##ing . yet , as more and more critics viewed that film they saw it as being purpose ##fully done . jason ever ##s is obviously not to ##shi ##ro mi ##fu ##ne , and his over ##act ##ing is exactly that . < br / > < br / > most of the actors in this b classic were rather good actors , minus ever ##s and the show ##girl ##s . if you watch this movie , you would have noticed ever ##s [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.404082 140278568785728 run_classifier.py:464] tokens: [CLS] i would have enjoyed this movie slightly more had not been for jason ( herb ) ever ##s constant harp ##ing on experiment . many early reviewers of the seven samurai accused to ##shi ##ro mi ##fu ##ne of over ##act ##ing . yet , as more and more critics viewed that film they saw it as being purpose ##fully done . jason ever ##s is obviously not to ##shi ##ro mi ##fu ##ne , and his over ##act ##ing is exactly that . < br / > < br / > most of the actors in this b classic were rather good actors , minus ever ##s and the show ##girl ##s . if you watch this movie , you would have noticed ever ##s [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2052 2031 5632 2023 3185 3621 2062 2018 2025 2042 2005 4463 1006 12810 1007 2412 2015 5377 14601 2075 2006 7551 1012 2116 2220 15814 1997 1996 2698 16352 5496 2000 6182 3217 2771 11263 2638 1997 2058 18908 2075 1012 2664 1010 2004 2062 1998 2062 4401 7021 2008 2143 2027 2387 2009 2004 2108 3800 7699 2589 1012 4463 2412 2015 2003 5525 2025 2000 6182 3217 2771 11263 2638 1010 1998 2010 2058 18908 2075 2003 3599 2008 1012 1026 7987 1013 1028 1026 7987 1013 1028 2087 1997 1996 5889 1999 2023 1038 4438 2020 2738 2204 5889 1010 15718 2412 2015 1998 1996 2265 15239 2015 1012 2065 2017 3422 2023 3185 1010 2017 2052 2031 4384 2412 2015 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.406056 140278568785728 run_classifier.py:465] input_ids: 101 1045 2052 2031 5632 2023 3185 3621 2062 2018 2025 2042 2005 4463 1006 12810 1007 2412 2015 5377 14601 2075 2006 7551 1012 2116 2220 15814 1997 1996 2698 16352 5496 2000 6182 3217 2771 11263 2638 1997 2058 18908 2075 1012 2664 1010 2004 2062 1998 2062 4401 7021 2008 2143 2027 2387 2009 2004 2108 3800 7699 2589 1012 4463 2412 2015 2003 5525 2025 2000 6182 3217 2771 11263 2638 1010 1998 2010 2058 18908 2075 2003 3599 2008 1012 1026 7987 1013 1028 1026 7987 1013 1028 2087 1997 1996 5889 1999 2023 1038 4438 2020 2738 2204 5889 1010 15718 2412 2015 1998 1996 2265 15239 2015 1012 2065 2017 3422 2023 3185 1010 2017 2052 2031 4384 2412 2015 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.408747 140278568785728 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.410477 140278568785728 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.412097 140278568785728 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.427858 140278568785728 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.430050 140278568785728 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] as winter approaches , our state - owned broadcaster , the abc , has decided for some reason to have a partial jane austen festival on sunday nights . this commenced with a twelve - year old movie length version of \" emma \" last sunday ; more recent versions of three other novels , \" persuasion \" , \" north ##anger abbey \" and \" mansfield park \" are to come . < br / > < br / > the curious thing about this production by a & e television networks , with script by the ever - reliable andrew davies , is that it appeared almost simultaneously with two much bigger budget movie versions , one starring g ##wyn ##eth pal ##tro ##w [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.431713 140278568785728 run_classifier.py:464] tokens: [CLS] as winter approaches , our state - owned broadcaster , the abc , has decided for some reason to have a partial jane austen festival on sunday nights . this commenced with a twelve - year old movie length version of \" emma \" last sunday ; more recent versions of three other novels , \" persuasion \" , \" north ##anger abbey \" and \" mansfield park \" are to come . < br / > < br / > the curious thing about this production by a & e television networks , with script by the ever - reliable andrew davies , is that it appeared almost simultaneously with two much bigger budget movie versions , one starring g ##wyn ##eth pal ##tro ##w [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2004 3467 8107 1010 2256 2110 1011 3079 11995 1010 1996 5925 1010 2038 2787 2005 2070 3114 2000 2031 1037 7704 4869 24177 2782 2006 4465 6385 1012 2023 8420 2007 1037 4376 1011 2095 2214 3185 3091 2544 1997 1000 5616 1000 2197 4465 1025 2062 3522 4617 1997 2093 2060 6002 1010 1000 27577 1000 1010 1000 2167 25121 6103 1000 1998 1000 15352 2380 1000 2024 2000 2272 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 8025 2518 2055 2023 2537 2011 1037 1004 1041 2547 6125 1010 2007 5896 2011 1996 2412 1011 10539 4080 9082 1010 2003 2008 2009 2596 2471 7453 2007 2048 2172 7046 5166 3185 4617 1010 2028 4626 1043 11761 11031 14412 13181 2860 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.434070 140278568785728 run_classifier.py:465] input_ids: 101 2004 3467 8107 1010 2256 2110 1011 3079 11995 1010 1996 5925 1010 2038 2787 2005 2070 3114 2000 2031 1037 7704 4869 24177 2782 2006 4465 6385 1012 2023 8420 2007 1037 4376 1011 2095 2214 3185 3091 2544 1997 1000 5616 1000 2197 4465 1025 2062 3522 4617 1997 2093 2060 6002 1010 1000 27577 1000 1010 1000 2167 25121 6103 1000 1998 1000 15352 2380 1000 2024 2000 2272 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 8025 2518 2055 2023 2537 2011 1037 1004 1041 2547 6125 1010 2007 5896 2011 1996 2412 1011 10539 4080 9082 1010 2003 2008 2009 2596 2471 7453 2007 2048 2172 7046 5166 3185 4617 1010 2028 4626 1043 11761 11031 14412 13181 2860 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.435457 140278568785728 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.436911 140278568785728 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.438456 140278568785728 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.446128 140278568785728 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.449466 140278568785728 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] there are similarities between ray lawrence ' s \" jin ##da ##by ##ne \" and his last movie \" lan ##tana \" a dead body and its rep ##er ##cus ##sions for already dysfunction ##al lives . but whereas \" lan ##tana \" offered some hope and resolution , \" jin ##da ##by ##ne \" leaves everything un ##res ##olved in a bleak way that will leave most viewers un ##sat ##is ##fied , perhaps even cheated . < br / > < br / > the storyline - the aftermath of a fisherman ' s discovery of a corpse floating in a remote river - is based on a short story by raymond carver . it became an element in robert alt ##man ' s [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.451352 140278568785728 run_classifier.py:464] tokens: [CLS] there are similarities between ray lawrence ' s \" jin ##da ##by ##ne \" and his last movie \" lan ##tana \" a dead body and its rep ##er ##cus ##sions for already dysfunction ##al lives . but whereas \" lan ##tana \" offered some hope and resolution , \" jin ##da ##by ##ne \" leaves everything un ##res ##olved in a bleak way that will leave most viewers un ##sat ##is ##fied , perhaps even cheated . < br / > < br / > the storyline - the aftermath of a fisherman ' s discovery of a corpse floating in a remote river - is based on a short story by raymond carver . it became an element in robert alt ##man ' s [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2045 2024 12319 2090 4097 5623 1005 1055 1000 9743 2850 3762 2638 1000 1998 2010 2197 3185 1000 17595 20496 1000 1037 2757 2303 1998 2049 16360 2121 7874 27466 2005 2525 28466 2389 3268 1012 2021 6168 1000 17595 20496 1000 3253 2070 3246 1998 5813 1010 1000 9743 2850 3762 2638 1000 3727 2673 4895 6072 16116 1999 1037 21657 2126 2008 2097 2681 2087 7193 4895 16846 2483 10451 1010 3383 2130 22673 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 9994 1011 1996 10530 1997 1037 19949 1005 1055 5456 1997 1037 11547 8274 1999 1037 6556 2314 1011 2003 2241 2006 1037 2460 2466 2011 7638 20163 1012 2009 2150 2019 5783 1999 2728 12456 2386 1005 1055 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.452902 140278568785728 run_classifier.py:465] input_ids: 101 2045 2024 12319 2090 4097 5623 1005 1055 1000 9743 2850 3762 2638 1000 1998 2010 2197 3185 1000 17595 20496 1000 1037 2757 2303 1998 2049 16360 2121 7874 27466 2005 2525 28466 2389 3268 1012 2021 6168 1000 17595 20496 1000 3253 2070 3246 1998 5813 1010 1000 9743 2850 3762 2638 1000 3727 2673 4895 6072 16116 1999 1037 21657 2126 2008 2097 2681 2087 7193 4895 16846 2483 10451 1010 3383 2130 22673 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 9994 1011 1996 10530 1997 1037 19949 1005 1055 5456 1997 1037 11547 8274 1999 1037 6556 2314 1011 2003 2241 2006 1037 2460 2466 2011 7638 20163 1012 2009 2150 2019 5783 1999 2728 12456 2386 1005 1055 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.454375 140278568785728 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.456010 140278568785728 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.457391 140278568785728 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.462316 140278568785728 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.464392 140278568785728 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] so i rented \" still crazy \" instead . when i described hardcore logo to the guy at the video store , he said that sounded kind of like still crazy . so i rented it . was i disappointed ? well , yes , as still crazy focuses on a classic rock band rather than a punk band , but that ' s ok . still crazy tells the story of the strange fruit , a rock band that broke up in the 70s at the peak of their popularity at a large rock festival . twenty years later , the band members are all struggling to make a living , and are offered the opportunity to play a concert at the twenty year anniversary [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.467104 140278568785728 run_classifier.py:464] tokens: [CLS] so i rented \" still crazy \" instead . when i described hardcore logo to the guy at the video store , he said that sounded kind of like still crazy . so i rented it . was i disappointed ? well , yes , as still crazy focuses on a classic rock band rather than a punk band , but that ' s ok . still crazy tells the story of the strange fruit , a rock band that broke up in the 70s at the peak of their popularity at a large rock festival . twenty years later , the band members are all struggling to make a living , and are offered the opportunity to play a concert at the twenty year anniversary [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2061 1045 12524 1000 2145 4689 1000 2612 1012 2043 1045 2649 13076 8154 2000 1996 3124 2012 1996 2678 3573 1010 2002 2056 2008 5015 2785 1997 2066 2145 4689 1012 2061 1045 12524 2009 1012 2001 1045 9364 1029 2092 1010 2748 1010 2004 2145 4689 7679 2006 1037 4438 2600 2316 2738 2084 1037 7196 2316 1010 2021 2008 1005 1055 7929 1012 2145 4689 4136 1996 2466 1997 1996 4326 5909 1010 1037 2600 2316 2008 3631 2039 1999 1996 17549 2012 1996 4672 1997 2037 6217 2012 1037 2312 2600 2782 1012 3174 2086 2101 1010 1996 2316 2372 2024 2035 8084 2000 2191 1037 2542 1010 1998 2024 3253 1996 4495 2000 2377 1037 4164 2012 1996 3174 2095 5315 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.469015 140278568785728 run_classifier.py:465] input_ids: 101 2061 1045 12524 1000 2145 4689 1000 2612 1012 2043 1045 2649 13076 8154 2000 1996 3124 2012 1996 2678 3573 1010 2002 2056 2008 5015 2785 1997 2066 2145 4689 1012 2061 1045 12524 2009 1012 2001 1045 9364 1029 2092 1010 2748 1010 2004 2145 4689 7679 2006 1037 4438 2600 2316 2738 2084 1037 7196 2316 1010 2021 2008 1005 1055 7929 1012 2145 4689 4136 1996 2466 1997 1996 4326 5909 1010 1037 2600 2316 2008 3631 2039 1999 1996 17549 2012 1996 4672 1997 2037 6217 2012 1037 2312 2600 2782 1012 3174 2086 2101 1010 1996 2316 2372 2024 2035 8084 2000 2191 1037 2542 1010 1998 2024 3253 1996 4495 2000 2377 1037 4164 2012 1996 3174 2095 5315 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.470619 140278568785728 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.472110 140278568785728 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.473477 140278568785728 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.479391 140278568785728 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.481433 140278568785728 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this is one of my favorite sports movies . dennis qu ##aid is moving and convincing in the part of a man who gave up his dream of being a baseball pitcher when his arm gave out on him . as a high school coach , he challenges his players to win the division championship by telling them he ' ll try out for a baseball team if they do . they win ( partly because of all the batting practice they take with a coach who can pitch over 90 miles an hour ) , and he keeps his side of the bargain - - and is signed ! < br / > < br / > if you have ever decided to try something [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.482996 140278568785728 run_classifier.py:464] tokens: [CLS] this is one of my favorite sports movies . dennis qu ##aid is moving and convincing in the part of a man who gave up his dream of being a baseball pitcher when his arm gave out on him . as a high school coach , he challenges his players to win the division championship by telling them he ' ll try out for a baseball team if they do . they win ( partly because of all the batting practice they take with a coach who can pitch over 90 miles an hour ) , and he keeps his side of the bargain - - and is signed ! < br / > < br / > if you have ever decided to try something [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2003 2028 1997 2026 5440 2998 5691 1012 6877 24209 14326 2003 3048 1998 13359 1999 1996 2112 1997 1037 2158 2040 2435 2039 2010 3959 1997 2108 1037 3598 8070 2043 2010 2849 2435 2041 2006 2032 1012 2004 1037 2152 2082 2873 1010 2002 7860 2010 2867 2000 2663 1996 2407 2528 2011 4129 2068 2002 1005 2222 3046 2041 2005 1037 3598 2136 2065 2027 2079 1012 2027 2663 1006 6576 2138 1997 2035 1996 9640 3218 2027 2202 2007 1037 2873 2040 2064 6510 2058 3938 2661 2019 3178 1007 1010 1998 2002 7906 2010 2217 1997 1996 17113 1011 1011 1998 2003 2772 999 1026 7987 1013 1028 1026 7987 1013 1028 2065 2017 2031 2412 2787 2000 3046 2242 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.484738 140278568785728 run_classifier.py:465] input_ids: 101 2023 2003 2028 1997 2026 5440 2998 5691 1012 6877 24209 14326 2003 3048 1998 13359 1999 1996 2112 1997 1037 2158 2040 2435 2039 2010 3959 1997 2108 1037 3598 8070 2043 2010 2849 2435 2041 2006 2032 1012 2004 1037 2152 2082 2873 1010 2002 7860 2010 2867 2000 2663 1996 2407 2528 2011 4129 2068 2002 1005 2222 3046 2041 2005 1037 3598 2136 2065 2027 2079 1012 2027 2663 1006 6576 2138 1997 2035 1996 9640 3218 2027 2202 2007 1037 2873 2040 2064 6510 2058 3938 2661 2019 3178 1007 1010 1998 2002 7906 2010 2217 1997 1996 17113 1011 1011 1998 2003 2772 999 1026 7987 1013 1028 1026 7987 1013 1028 2065 2017 2031 2412 2787 2000 3046 2242 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.486357 140278568785728 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.488828 140278568785728 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:22:20.491085 140278568785728 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:01.792687 140278568785728 run_classifier.py:774] Writing example 10000 of 20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.656774 140278568785728 run_classifier.py:774] Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.662062 140278568785728 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.663854 140278568785728 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i love this movie , jo ##uve ##t , ar ##lett ##y , b ##lier , car ##ne . . . almost everything has already been said about the movie , but there is one detail i ' d like to shed some light onto : no footage of the real , still standing , hotel du nord ( is it still ? i heard it was to be demolished . . . ) has been used for the movie - the whole scene has been rebuilt on set , the main reason being that they could not stop the traffic on the st martin canal for several weeks . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.665243 140278568785728 run_classifier.py:464] tokens: [CLS] i love this movie , jo ##uve ##t , ar ##lett ##y , b ##lier , car ##ne . . . almost everything has already been said about the movie , but there is one detail i ' d like to shed some light onto : no footage of the real , still standing , hotel du nord ( is it still ? i heard it was to be demolished . . . ) has been used for the movie - the whole scene has been rebuilt on set , the main reason being that they could not stop the traffic on the st martin canal for several weeks . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2293 2023 3185 1010 8183 22909 2102 1010 12098 20897 2100 1010 1038 14355 1010 2482 2638 1012 1012 1012 2471 2673 2038 2525 2042 2056 2055 1996 3185 1010 2021 2045 2003 2028 6987 1045 1005 1040 2066 2000 8328 2070 2422 3031 1024 2053 8333 1997 1996 2613 1010 2145 3061 1010 3309 4241 13926 1006 2003 2009 2145 1029 1045 2657 2009 2001 2000 2022 7002 1012 1012 1012 1007 2038 2042 2109 2005 1996 3185 1011 1996 2878 3496 2038 2042 7183 2006 2275 1010 1996 2364 3114 2108 2008 2027 2071 2025 2644 1996 4026 2006 1996 2358 3235 5033 2005 2195 3134 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.667209 140278568785728 run_classifier.py:465] input_ids: 101 1045 2293 2023 3185 1010 8183 22909 2102 1010 12098 20897 2100 1010 1038 14355 1010 2482 2638 1012 1012 1012 2471 2673 2038 2525 2042 2056 2055 1996 3185 1010 2021 2045 2003 2028 6987 1045 1005 1040 2066 2000 8328 2070 2422 3031 1024 2053 8333 1997 1996 2613 1010 2145 3061 1010 3309 4241 13926 1006 2003 2009 2145 1029 1045 2657 2009 2001 2000 2022 7002 1012 1012 1012 1007 2038 2042 2109 2005 1996 3185 1011 1996 2878 3496 2038 2042 7183 2006 2275 1010 1996 2364 3114 2108 2008 2027 2071 2025 2644 1996 4026 2006 1996 2358 3235 5033 2005 2195 3134 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.668592 140278568785728 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.670286 140278568785728 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.671405 140278568785728 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.675663 140278568785728 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.677073 140278568785728 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] * * * spoil ##ers * < br / > < br / > my dad had taped this movie for me when i was 3 . by age 5 , i had watched it over 400 times . i just watched it and watched it . and i still do today ! it has a grim storyline , a lamb ' s mother is killed by a wolf - - a very emotional scene - - and wants to become a wolf , like him . after years of training , the lamb is made into a really really evil looking thing . he and the wolf travel to his old barn , but he cannot kill the lamb ##s , no matter how much [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.678509 140278568785728 run_classifier.py:464] tokens: [CLS] * * * spoil ##ers * < br / > < br / > my dad had taped this movie for me when i was 3 . by age 5 , i had watched it over 400 times . i just watched it and watched it . and i still do today ! it has a grim storyline , a lamb ' s mother is killed by a wolf - - a very emotional scene - - and wants to become a wolf , like him . after years of training , the lamb is made into a really really evil looking thing . he and the wolf travel to his old barn , but he cannot kill the lamb ##s , no matter how much [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1008 1008 1008 27594 2545 1008 1026 7987 1013 1028 1026 7987 1013 1028 2026 3611 2018 19374 2023 3185 2005 2033 2043 1045 2001 1017 1012 2011 2287 1019 1010 1045 2018 3427 2009 2058 4278 2335 1012 1045 2074 3427 2009 1998 3427 2009 1012 1998 1045 2145 2079 2651 999 2009 2038 1037 11844 9994 1010 1037 12559 1005 1055 2388 2003 2730 2011 1037 4702 1011 1011 1037 2200 6832 3496 1011 1011 1998 4122 2000 2468 1037 4702 1010 2066 2032 1012 2044 2086 1997 2731 1010 1996 12559 2003 2081 2046 1037 2428 2428 4763 2559 2518 1012 2002 1998 1996 4702 3604 2000 2010 2214 8659 1010 2021 2002 3685 3102 1996 12559 2015 1010 2053 3043 2129 2172 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.679863 140278568785728 run_classifier.py:465] input_ids: 101 1008 1008 1008 27594 2545 1008 1026 7987 1013 1028 1026 7987 1013 1028 2026 3611 2018 19374 2023 3185 2005 2033 2043 1045 2001 1017 1012 2011 2287 1019 1010 1045 2018 3427 2009 2058 4278 2335 1012 1045 2074 3427 2009 1998 3427 2009 1012 1998 1045 2145 2079 2651 999 2009 2038 1037 11844 9994 1010 1037 12559 1005 1055 2388 2003 2730 2011 1037 4702 1011 1011 1037 2200 6832 3496 1011 1011 1998 4122 2000 2468 1037 4702 1010 2066 2032 1012 2044 2086 1997 2731 1010 1996 12559 2003 2081 2046 1037 2428 2428 4763 2559 2518 1012 2002 1998 1996 4702 3604 2000 2010 2214 8659 1010 2021 2002 3685 3102 1996 12559 2015 1010 2053 3043 2129 2172 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.681605 140278568785728 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.683023 140278568785728 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.684176 140278568785728 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.698542 140278568785728 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.700506 140278568785728 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] as is often the case , films about self - lo ##athing characters do not usually make for good drama . ' download ##ing nancy ' is no exception . it ' s supposedly based on a true story about a woman who ' s murdered at her own request by someone she meets over the internet . < br / > < br / > the protagonist is nancy ( maria bell ##o ) who is married to albert ( rufus se ##well ) . albert is a successful software developer who has developed a golf game which his company has successfully marketed to various bars and bar / restaurants . unlike most human beings , albert has virtually no positive attributes ( except for [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.702281 140278568785728 run_classifier.py:464] tokens: [CLS] as is often the case , films about self - lo ##athing characters do not usually make for good drama . ' download ##ing nancy ' is no exception . it ' s supposedly based on a true story about a woman who ' s murdered at her own request by someone she meets over the internet . < br / > < br / > the protagonist is nancy ( maria bell ##o ) who is married to albert ( rufus se ##well ) . albert is a successful software developer who has developed a golf game which his company has successfully marketed to various bars and bar / restaurants . unlike most human beings , albert has virtually no positive attributes ( except for [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2004 2003 2411 1996 2553 1010 3152 2055 2969 1011 8840 22314 3494 2079 2025 2788 2191 2005 2204 3689 1012 1005 8816 2075 7912 1005 2003 2053 6453 1012 2009 1005 1055 10743 2241 2006 1037 2995 2466 2055 1037 2450 2040 1005 1055 7129 2012 2014 2219 5227 2011 2619 2016 6010 2058 1996 4274 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 10191 2003 7912 1006 3814 4330 2080 1007 2040 2003 2496 2000 4789 1006 18316 7367 4381 1007 1012 4789 2003 1037 3144 4007 9722 2040 2038 2764 1037 5439 2208 2029 2010 2194 2038 5147 11625 2000 2536 6963 1998 3347 1013 7884 1012 4406 2087 2529 9552 1010 4789 2038 8990 2053 3893 12332 1006 3272 2005 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.703612 140278568785728 run_classifier.py:465] input_ids: 101 2004 2003 2411 1996 2553 1010 3152 2055 2969 1011 8840 22314 3494 2079 2025 2788 2191 2005 2204 3689 1012 1005 8816 2075 7912 1005 2003 2053 6453 1012 2009 1005 1055 10743 2241 2006 1037 2995 2466 2055 1037 2450 2040 1005 1055 7129 2012 2014 2219 5227 2011 2619 2016 6010 2058 1996 4274 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 10191 2003 7912 1006 3814 4330 2080 1007 2040 2003 2496 2000 4789 1006 18316 7367 4381 1007 1012 4789 2003 1037 3144 4007 9722 2040 2038 2764 1037 5439 2208 2029 2010 2194 2038 5147 11625 2000 2536 6963 1998 3347 1013 7884 1012 4406 2087 2529 9552 1010 4789 2038 8990 2053 3893 12332 1006 3272 2005 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.704947 140278568785728 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.706356 140278568785728 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.707682 140278568785728 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.712414 140278568785728 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.713580 140278568785728 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i have to totally disagree with the other comment concerning this movie . the visual effects complement the supernatural themes of the movie and do not det ##rac ##t from the plot furthermore i loved how this move was unlike crouch ##ing tiger because this time the sword action had no strings attached and most of the time you can see the action up close . < br / > < br / > i think western audiences will be very confused with 2 scenes one of which involves a monk trying to burn himself alive and the other concerning the villagers chanting that it is the end of the world . the mentioned scenes are derived from certain interpretations of maha ##yana buddhist text ( [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.714691 140278568785728 run_classifier.py:464] tokens: [CLS] i have to totally disagree with the other comment concerning this movie . the visual effects complement the supernatural themes of the movie and do not det ##rac ##t from the plot furthermore i loved how this move was unlike crouch ##ing tiger because this time the sword action had no strings attached and most of the time you can see the action up close . < br / > < br / > i think western audiences will be very confused with 2 scenes one of which involves a monk trying to burn himself alive and the other concerning the villagers chanting that it is the end of the world . the mentioned scenes are derived from certain interpretations of maha ##yana buddhist text ( [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2031 2000 6135 21090 2007 1996 2060 7615 7175 2023 3185 1012 1996 5107 3896 13711 1996 11189 6991 1997 1996 3185 1998 2079 2025 20010 22648 2102 2013 1996 5436 7297 1045 3866 2129 2023 2693 2001 4406 21676 2075 6816 2138 2023 2051 1996 4690 2895 2018 2053 7817 4987 1998 2087 1997 1996 2051 2017 2064 2156 1996 2895 2039 2485 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2228 2530 9501 2097 2022 2200 5457 2007 1016 5019 2028 1997 2029 7336 1037 8284 2667 2000 6402 2370 4142 1998 1996 2060 7175 1996 11904 22417 2008 2009 2003 1996 2203 1997 1996 2088 1012 1996 3855 5019 2024 5173 2013 3056 15931 1997 24404 16811 7992 3793 1006 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.716050 140278568785728 run_classifier.py:465] input_ids: 101 1045 2031 2000 6135 21090 2007 1996 2060 7615 7175 2023 3185 1012 1996 5107 3896 13711 1996 11189 6991 1997 1996 3185 1998 2079 2025 20010 22648 2102 2013 1996 5436 7297 1045 3866 2129 2023 2693 2001 4406 21676 2075 6816 2138 2023 2051 1996 4690 2895 2018 2053 7817 4987 1998 2087 1997 1996 2051 2017 2064 2156 1996 2895 2039 2485 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2228 2530 9501 2097 2022 2200 5457 2007 1016 5019 2028 1997 2029 7336 1037 8284 2667 2000 6402 2370 4142 1998 1996 2060 7175 1996 11904 22417 2008 2009 2003 1996 2203 1997 1996 2088 1012 1996 3855 5019 2024 5173 2013 3056 15931 1997 24404 16811 7992 3793 1006 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.717502 140278568785728 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.718684 140278568785728 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.719766 140278568785728 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.738537 140278568785728 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.740338 140278568785728 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] blood castle ( aka scream of the demon lover , altar of blood , ivan ##na - - the best , but least exploitation cinema - sounding title , and so on ) is a very traditional gothic romance film . that means that it has big , creepy castles , a heads ##tron ##g young woman , a mysterious older man , hints of horror and the supernatural , and romance elements in the contemporary sense of that genre term . it also means that it is very deliberately paced , and that the film will work best for horror ma ##ven ##s who are big fans of under ##sta ##tem ##ent . if you love films like robert wise ' s the haunting ( [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.741753 140278568785728 run_classifier.py:464] tokens: [CLS] blood castle ( aka scream of the demon lover , altar of blood , ivan ##na - - the best , but least exploitation cinema - sounding title , and so on ) is a very traditional gothic romance film . that means that it has big , creepy castles , a heads ##tron ##g young woman , a mysterious older man , hints of horror and the supernatural , and romance elements in the contemporary sense of that genre term . it also means that it is very deliberately paced , and that the film will work best for horror ma ##ven ##s who are big fans of under ##sta ##tem ##ent . if you love films like robert wise ' s the haunting ( [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2668 3317 1006 9875 6978 1997 1996 5698 7089 1010 9216 1997 2668 1010 7332 2532 1011 1011 1996 2190 1010 2021 2560 14427 5988 1011 9391 2516 1010 1998 2061 2006 1007 2003 1037 2200 3151 7788 7472 2143 1012 2008 2965 2008 2009 2038 2502 1010 17109 15618 1010 1037 4641 15312 2290 2402 2450 1010 1037 8075 3080 2158 1010 20385 1997 5469 1998 1996 11189 1010 1998 7472 3787 1999 1996 3824 3168 1997 2008 6907 2744 1012 2009 2036 2965 2008 2009 2003 2200 9969 13823 1010 1998 2008 1996 2143 2097 2147 2190 2005 5469 5003 8159 2015 2040 2024 2502 4599 1997 2104 9153 18532 4765 1012 2065 2017 2293 3152 2066 2728 7968 1005 1055 1996 20161 1006 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.743038 140278568785728 run_classifier.py:465] input_ids: 101 2668 3317 1006 9875 6978 1997 1996 5698 7089 1010 9216 1997 2668 1010 7332 2532 1011 1011 1996 2190 1010 2021 2560 14427 5988 1011 9391 2516 1010 1998 2061 2006 1007 2003 1037 2200 3151 7788 7472 2143 1012 2008 2965 2008 2009 2038 2502 1010 17109 15618 1010 1037 4641 15312 2290 2402 2450 1010 1037 8075 3080 2158 1010 20385 1997 5469 1998 1996 11189 1010 1998 7472 3787 1999 1996 3824 3168 1997 2008 6907 2744 1012 2009 2036 2965 2008 2009 2003 2200 9969 13823 1010 1998 2008 1996 2143 2097 2147 2190 2005 5469 5003 8159 2015 2040 2024 2502 4599 1997 2104 9153 18532 4765 1012 2065 2017 2293 3152 2066 2728 7968 1005 1055 1996 20161 1006 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.744221 140278568785728 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.745962 140278568785728 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:23:41.746996 140278568785728 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    }
   ],
   "source": [
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, text_a = x[DATA_COLUMN], text_b = None, label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "# We'll set sequences to be at most 128 tokens long.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/eugenet/final_project/trained_models/imdb_google_example_large', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f94c7d83e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:24:01.632804 140278568785728 estimator.py:201] Using config: {'_model_dir': '/home/eugenet/final_project/trained_models/imdb_google_example_large', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f94c7d83e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir='/home/eugenet/final_project/trained_models/imdb_google_example_large',\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n",
    "\n",
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:24:11.283242 140278568785728 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:24:18.984485 140278568785728 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-ca03218f28a6>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 01:24:19.234070 140278568785728 deprecation.py:506] From <ipython-input-11-ca03218f28a6>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eugenet/miniconda3/envs/bert/lib/python3.7/site-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 01:24:19.313517 140278568785728 deprecation.py:323] From /home/eugenet/miniconda3/envs/bert/lib/python3.7/site-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eugenet/miniconda3/envs/bert/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 01:24:19.444472 140278568785728 deprecation.py:323] From /home/eugenet/miniconda3/envs/bert/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "/home/eugenet/miniconda3/envs/bert/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eugenet/miniconda3/envs/bert/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 01:24:40.377038 140278568785728 deprecation.py:323] From /home/eugenet/miniconda3/envs/bert/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:24:45.194735 140278568785728 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:24:45.200835 140278568785728 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:24:54.992250 140278568785728 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:25:19.404735 140278568785728 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:25:20.053061 140278568785728 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /home/eugenet/final_project/trained_models/imdb_google_example_large/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:25:43.310776 140278568785728 basic_session_run_hooks.py:594] Saving checkpoints for 0 into /home/eugenet/final_project/trained_models/imdb_google_example_large/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.96802104, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0410 01:28:01.028592 140278568785728 basic_session_run_hooks.py:249] loss = 0.96802104, step = 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=200)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
