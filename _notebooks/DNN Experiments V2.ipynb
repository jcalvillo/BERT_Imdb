{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series of experiments run on Bert data *after* all the sentences have already been embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tensorflow.estimator import BaselineClassifier\n",
    "from tensorflow.python.estimator.canned.dnn import DNNClassifier\n",
    "from tensorflow.python.estimator.run_config import RunConfig\n",
    "from tensorflow.python.estimator.training import TrainSpec, EvalSpec, train_and_evaluate\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Input. Assumes an 80% training, 20% dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_fn(data_dir, num_examples=None, num_epochs=10):\n",
    "    data_files = os.listdir(data_dir)\n",
    "    \n",
    "    # open pre-embedded data\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for data_file in data_files:\n",
    "        with open(os.path.join(data_dir, data_file), 'rb') as f:\n",
    "            features, labels = pickle.load(f)\n",
    "            feature_list.append(features)\n",
    "            label_list.append(labels)\n",
    "    features = np.concatenate(feature_list)\n",
    "    labels = [label for labels in label_list for label in labels]\n",
    "    \n",
    "    # split into train and dev set\n",
    "    train_features = features[0:int(0.8*len(features))]\n",
    "    train_labels = labels[0:int(0.8*len(features))]\n",
    "    dev_features = features[int(0.8*len(features)):len(features)]\n",
    "    dev_labels = labels[int(0.8*len(features)):len(features)]\n",
    "    \n",
    "    train_labels = np.array(train_labels).astype('int32')\n",
    "    dev_labels = np.array(dev_labels).astype('int32')\n",
    "    \n",
    "    if num_examples is not None:\n",
    "        train_features = train_features[0:num_examples]\n",
    "        train_labels = train_labels[0:num_examples]\n",
    "    \n",
    "#     print('{} train data points'.format(len(train_features)))\n",
    "#     print('{} dev data points'.format(len(dev_features)))\n",
    "    \n",
    "    train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'feature': train_features},\n",
    "        y=train_labels,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    dev_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'feature': dev_features},\n",
    "        y=dev_labels,\n",
    "        num_epochs=1,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    return (train_fn, dev_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_DNN(bert_model, hidden_units, learning_rate, dropout_rate, \n",
    "                           train_num_epochs, input_size, activation_function, \n",
    "                           optimizer, output_type):\n",
    "    classifier = 'DNN'\n",
    "    config = tf.ConfigProto()\n",
    "    run_config = RunConfig(model_dir='/home/eugenet/final_project/trained_models/imdb_{}_{}_input{}_epochs{}_hu{}_lr{}_dropout{}_activation{}_opt{}'.format(\n",
    "        bert_model, classifier, input_size, train_num_epochs, '_'.join([str(x) for x in hidden_units]), learning_rate, dropout_rate, activation_function, optimizer),\n",
    "                       session_config=config,\n",
    "                       save_checkpoints_steps=1000)\n",
    "    embedding_size = None\n",
    "    if 'large' in bert_model:\n",
    "        embedding_size = 1024\n",
    "    elif 'small' in bert_model:\n",
    "        embedding_size = 768\n",
    "\n",
    "    activation_fn = None\n",
    "    if activation_function == 'relu':\n",
    "        activation_fn = tf.nn.relu\n",
    "    elif activation_function == 'softmax':\n",
    "        activation_fn = tf.nn.softmax\n",
    "    elif activation_function == 'tanh':\n",
    "        activation_fn = tf.nn.tanh\n",
    "    \n",
    "    opt = None\n",
    "    if optimizer == 'AdaGrad':\n",
    "        opt = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "    elif optimizer == 'AdamW':\n",
    "        opt = tf.contrib.opt.AdamWOptimizer(learning_rate=learning_rate, weight_decay=0.01)\n",
    "    estimator = DNNClassifier(\n",
    "        hidden_units=hidden_units,\n",
    "        feature_columns=[tf.feature_column.numeric_column('feature', shape=(embedding_size,))],\n",
    "        n_classes=2,\n",
    "        config=run_config,\n",
    "        optimizer=opt,\n",
    "        dropout=dropout_rate,\n",
    "        activation_fn=activation_fn)\n",
    "    train_input_fn, dev_input_fn = get_input_fn('/home/eugenet/final_project/cached_data/{}/'.format(bert_model), input_size, train_num_epochs)\n",
    "    estimator.train(input_fn=train_input_fn)\n",
    "    if output_type == 'accuracy':\n",
    "        return estimator.evaluate(dev_input_fn)\n",
    "    elif output_type == 'predictions':\n",
    "        return estimator.predict(dev_input_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defaults\n",
    "Defaults to use for all parameters (generally a \"good\" set of parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = [1024]\n",
    "learning_rate = 0.003\n",
    "bert_model = 'train_uncased_large_max200'\n",
    "dropout_rate = 0.1\n",
    "train_num_epochs = 30\n",
    "input_size = None # all\n",
    "activation_function = 'relu'\n",
    "optimizer = 'AdaGrad'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Number of Hidden Units\n",
    "Assuming we only have one hidden layer for now (\"fine-tuning\"). We pick out 1024 especially because that's the number of dimensions in the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[1]_Hidden_Units</th>\n",
       "      <th>[2]_Hidden_Units</th>\n",
       "      <th>[5]_Hidden_Units</th>\n",
       "      <th>[10]_Hidden_Units</th>\n",
       "      <th>[50]_Hidden_Units</th>\n",
       "      <th>[100]_Hidden_Units</th>\n",
       "      <th>[500]_Hidden_Units</th>\n",
       "      <th>[1024]_Hidden_Units</th>\n",
       "      <th>[2000]_Hidden_Units</th>\n",
       "      <th>[10000]_Hidden_Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866400</td>\n",
       "      <td>0.869600</td>\n",
       "      <td>0.878200</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.886800</td>\n",
       "      <td>0.891200</td>\n",
       "      <td>0.892600</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.926781</td>\n",
       "      <td>0.934805</td>\n",
       "      <td>0.947532</td>\n",
       "      <td>0.951053</td>\n",
       "      <td>0.951325</td>\n",
       "      <td>0.953322</td>\n",
       "      <td>0.954126</td>\n",
       "      <td>0.954662</td>\n",
       "      <td>0.956050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.749800</td>\n",
       "      <td>0.927192</td>\n",
       "      <td>0.941591</td>\n",
       "      <td>0.947597</td>\n",
       "      <td>0.950913</td>\n",
       "      <td>0.951102</td>\n",
       "      <td>0.952879</td>\n",
       "      <td>0.953752</td>\n",
       "      <td>0.954036</td>\n",
       "      <td>0.955395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.693156</td>\n",
       "      <td>0.445693</td>\n",
       "      <td>0.440960</td>\n",
       "      <td>0.295502</td>\n",
       "      <td>0.285291</td>\n",
       "      <td>0.281934</td>\n",
       "      <td>0.276378</td>\n",
       "      <td>0.273639</td>\n",
       "      <td>0.279595</td>\n",
       "      <td>0.268213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>86.644455</td>\n",
       "      <td>55.711567</td>\n",
       "      <td>55.120014</td>\n",
       "      <td>36.937691</td>\n",
       "      <td>35.661438</td>\n",
       "      <td>35.241711</td>\n",
       "      <td>34.547279</td>\n",
       "      <td>34.204906</td>\n",
       "      <td>34.949368</td>\n",
       "      <td>33.526642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.887807</td>\n",
       "      <td>0.841211</td>\n",
       "      <td>0.867184</td>\n",
       "      <td>0.865019</td>\n",
       "      <td>0.876265</td>\n",
       "      <td>0.881138</td>\n",
       "      <td>0.889639</td>\n",
       "      <td>0.858203</td>\n",
       "      <td>0.890471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.499981</td>\n",
       "      <td>0.382510</td>\n",
       "      <td>0.631203</td>\n",
       "      <td>0.511443</td>\n",
       "      <td>0.521093</td>\n",
       "      <td>0.505989</td>\n",
       "      <td>0.509795</td>\n",
       "      <td>0.499574</td>\n",
       "      <td>0.534866</td>\n",
       "      <td>0.499886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.999200</td>\n",
       "      <td>0.838800</td>\n",
       "      <td>0.911200</td>\n",
       "      <td>0.893200</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.900800</td>\n",
       "      <td>0.904400</td>\n",
       "      <td>0.896400</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>0.900800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>9376.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      [1]_Hidden_Units  [2]_Hidden_Units  [5]_Hidden_Units  \\\n",
       "accuracy                      0.500000          0.866400          0.869600   \n",
       "accuracy_baseline             0.500000          0.500000          0.500000   \n",
       "auc                           0.500000          0.926781          0.934805   \n",
       "auc_precision_recall          0.749800          0.927192          0.941591   \n",
       "average_loss                  0.693156          0.445693          0.440960   \n",
       "label/mean                    0.500000          0.500000          0.500000   \n",
       "loss                         86.644455         55.711567         55.120014   \n",
       "precision                     0.500000          0.887807          0.841211   \n",
       "prediction/mean               0.499981          0.382510          0.631203   \n",
       "recall                        0.999200          0.838800          0.911200   \n",
       "global_step                9376.000000       4688.000000       4688.000000   \n",
       "\n",
       "                      [10]_Hidden_Units  [50]_Hidden_Units  \\\n",
       "accuracy                       0.878200           0.884000   \n",
       "accuracy_baseline              0.500000           0.500000   \n",
       "auc                            0.947532           0.951053   \n",
       "auc_precision_recall           0.947597           0.950913   \n",
       "average_loss                   0.295502           0.285291   \n",
       "label/mean                     0.500000           0.500000   \n",
       "loss                          36.937691          35.661438   \n",
       "precision                      0.867184           0.865019   \n",
       "prediction/mean                0.511443           0.521093   \n",
       "recall                         0.893200           0.910000   \n",
       "global_step                 4688.000000        4688.000000   \n",
       "\n",
       "                      [100]_Hidden_Units  [500]_Hidden_Units  \\\n",
       "accuracy                        0.886800            0.891200   \n",
       "accuracy_baseline               0.500000            0.500000   \n",
       "auc                             0.951325            0.953322   \n",
       "auc_precision_recall            0.951102            0.952879   \n",
       "average_loss                    0.281934            0.276378   \n",
       "label/mean                      0.500000            0.500000   \n",
       "loss                           35.241711           34.547279   \n",
       "precision                       0.876265            0.881138   \n",
       "prediction/mean                 0.505989            0.509795   \n",
       "recall                          0.900800            0.904400   \n",
       "global_step                  4688.000000         4688.000000   \n",
       "\n",
       "                      [1024]_Hidden_Units  [2000]_Hidden_Units  \\\n",
       "accuracy                         0.892600             0.886000   \n",
       "accuracy_baseline                0.500000             0.500000   \n",
       "auc                              0.954126             0.954662   \n",
       "auc_precision_recall             0.953752             0.954036   \n",
       "average_loss                     0.273639             0.279595   \n",
       "label/mean                       0.500000             0.500000   \n",
       "loss                            34.204906            34.949368   \n",
       "precision                        0.889639             0.858203   \n",
       "prediction/mean                  0.499574             0.534866   \n",
       "recall                           0.896400             0.924800   \n",
       "global_step                   4688.000000          4688.000000   \n",
       "\n",
       "                      [10000]_Hidden_Units  \n",
       "accuracy                          0.895000  \n",
       "accuracy_baseline                 0.500000  \n",
       "auc                               0.956050  \n",
       "auc_precision_recall              0.955395  \n",
       "average_loss                      0.268213  \n",
       "label/mean                        0.500000  \n",
       "loss                             33.526642  \n",
       "precision                         0.890471  \n",
       "prediction/mean                   0.499886  \n",
       "recall                            0.900800  \n",
       "global_step                    4688.000000  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units_list = [[1], [2], [5], [10], [50], [100], [500], [1024], [2000], [10000]]\n",
    "\n",
    "res = []\n",
    "for hu in hidden_units_list:\n",
    "    result = train_and_evaluate_DNN(bert_model, hu, learning_rate, dropout_rate, train_num_epochs, input_size, activation_function, optimizer, 'accuracy')\n",
    "    df_result = pd.DataFrame.from_dict(result, orient='index', columns=['{}_Hidden_Units'.format(hu)])\n",
    "    res.append(df_result)\n",
    "pd.concat(res, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 1\n",
      "Progress 2\n",
      "Progress 5\n",
      "Progress 10\n",
      "Progress 20\n",
      "Progress 30\n",
      "Progress 40\n",
      "Progress 50\n",
      "Progress 100\n",
      "Progress 150\n",
      "Progress 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "      <th>[10000]_Epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873400</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.888600</td>\n",
       "      <td>0.885800</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.883400</td>\n",
       "      <td>0.896800</td>\n",
       "      <td>0.893800</td>\n",
       "      <td>0.888800</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.940479</td>\n",
       "      <td>0.945295</td>\n",
       "      <td>0.949209</td>\n",
       "      <td>0.952301</td>\n",
       "      <td>0.954016</td>\n",
       "      <td>0.957141</td>\n",
       "      <td>0.956707</td>\n",
       "      <td>0.957187</td>\n",
       "      <td>0.957121</td>\n",
       "      <td>0.955594</td>\n",
       "      <td>0.954894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.940168</td>\n",
       "      <td>0.945182</td>\n",
       "      <td>0.949012</td>\n",
       "      <td>0.952120</td>\n",
       "      <td>0.953607</td>\n",
       "      <td>0.956190</td>\n",
       "      <td>0.955996</td>\n",
       "      <td>0.956493</td>\n",
       "      <td>0.956405</td>\n",
       "      <td>0.955305</td>\n",
       "      <td>0.955739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.318056</td>\n",
       "      <td>0.302333</td>\n",
       "      <td>0.287993</td>\n",
       "      <td>0.279030</td>\n",
       "      <td>0.280741</td>\n",
       "      <td>0.270329</td>\n",
       "      <td>0.280951</td>\n",
       "      <td>0.265619</td>\n",
       "      <td>0.280871</td>\n",
       "      <td>0.300794</td>\n",
       "      <td>0.326381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>39.756992</td>\n",
       "      <td>37.791618</td>\n",
       "      <td>35.999123</td>\n",
       "      <td>34.878803</td>\n",
       "      <td>35.092659</td>\n",
       "      <td>33.791084</td>\n",
       "      <td>35.118931</td>\n",
       "      <td>33.202381</td>\n",
       "      <td>35.108852</td>\n",
       "      <td>37.599197</td>\n",
       "      <td>40.797680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.866641</td>\n",
       "      <td>0.885266</td>\n",
       "      <td>0.879269</td>\n",
       "      <td>0.886282</td>\n",
       "      <td>0.861371</td>\n",
       "      <td>0.872463</td>\n",
       "      <td>0.850713</td>\n",
       "      <td>0.899356</td>\n",
       "      <td>0.883522</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.897581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.511703</td>\n",
       "      <td>0.478039</td>\n",
       "      <td>0.494844</td>\n",
       "      <td>0.495509</td>\n",
       "      <td>0.533123</td>\n",
       "      <td>0.519556</td>\n",
       "      <td>0.546171</td>\n",
       "      <td>0.494667</td>\n",
       "      <td>0.513091</td>\n",
       "      <td>0.513341</td>\n",
       "      <td>0.492930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.886400</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.885600</td>\n",
       "      <td>0.891600</td>\n",
       "      <td>0.919600</td>\n",
       "      <td>0.911200</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.893600</td>\n",
       "      <td>0.907200</td>\n",
       "      <td>0.902400</td>\n",
       "      <td>0.890400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>157.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>782.000000</td>\n",
       "      <td>1563.000000</td>\n",
       "      <td>3125.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>6250.000000</td>\n",
       "      <td>7813.000000</td>\n",
       "      <td>15625.000000</td>\n",
       "      <td>23438.000000</td>\n",
       "      <td>31250.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      [10000]_Epochs  [10000]_Epochs  [10000]_Epochs  \\\n",
       "accuracy                    0.875000        0.873400        0.882000   \n",
       "accuracy_baseline           0.500000        0.500000        0.500000   \n",
       "auc                         0.940479        0.945295        0.949209   \n",
       "auc_precision_recall        0.940168        0.945182        0.949012   \n",
       "average_loss                0.318056        0.302333        0.287993   \n",
       "label/mean                  0.500000        0.500000        0.500000   \n",
       "loss                       39.756992       37.791618       35.999123   \n",
       "precision                   0.866641        0.885266        0.879269   \n",
       "prediction/mean             0.511703        0.478039        0.494844   \n",
       "recall                      0.886400        0.858000        0.885600   \n",
       "global_step               157.000000      313.000000      782.000000   \n",
       "\n",
       "                      [10000]_Epochs  [10000]_Epochs  [10000]_Epochs  \\\n",
       "accuracy                    0.888600        0.885800        0.889000   \n",
       "accuracy_baseline           0.500000        0.500000        0.500000   \n",
       "auc                         0.952301        0.954016        0.957141   \n",
       "auc_precision_recall        0.952120        0.953607        0.956190   \n",
       "average_loss                0.279030        0.280741        0.270329   \n",
       "label/mean                  0.500000        0.500000        0.500000   \n",
       "loss                       34.878803       35.092659       33.791084   \n",
       "precision                   0.886282        0.861371        0.872463   \n",
       "prediction/mean             0.495509        0.533123        0.519556   \n",
       "recall                      0.891600        0.919600        0.911200   \n",
       "global_step              1563.000000     3125.000000     9376.000000   \n",
       "\n",
       "                      [10000]_Epochs  [10000]_Epochs  [10000]_Epochs  \\\n",
       "accuracy                    0.883400        0.896800        0.893800   \n",
       "accuracy_baseline           0.500000        0.500000        0.500000   \n",
       "auc                         0.956707        0.957187        0.957121   \n",
       "auc_precision_recall        0.955996        0.956493        0.956405   \n",
       "average_loss                0.280951        0.265619        0.280871   \n",
       "label/mean                  0.500000        0.500000        0.500000   \n",
       "loss                       35.118931       33.202381       35.108852   \n",
       "precision                   0.850713        0.899356        0.883522   \n",
       "prediction/mean             0.546171        0.494667        0.513091   \n",
       "recall                      0.930000        0.893600        0.907200   \n",
       "global_step              6250.000000     7813.000000    15625.000000   \n",
       "\n",
       "                      [10000]_Epochs  [10000]_Epochs  \n",
       "accuracy                    0.888800        0.894400  \n",
       "accuracy_baseline           0.500000        0.500000  \n",
       "auc                         0.955594        0.954894  \n",
       "auc_precision_recall        0.955305        0.955739  \n",
       "average_loss                0.300794        0.326381  \n",
       "label/mean                  0.500000        0.500000  \n",
       "loss                       37.599197       40.797680  \n",
       "precision                   0.878505        0.897581  \n",
       "prediction/mean             0.513341        0.492930  \n",
       "recall                      0.902400        0.890400  \n",
       "global_step             23438.000000    31250.000000  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_epochs_list = [1, 2, 5, 10, 20, 30, 40, 50, 100, 150, 200]\n",
    "\n",
    "res = []\n",
    "for tne in train_num_epochs_list:\n",
    "    print('Progress {}'.format(tne))\n",
    "    result = train_and_evaluate_DNN(bert_model, hidden_units, learning_rate, dropout_rate, tne, input_size, activation_function, optimizer, 'accuracy')\n",
    "    df_result = pd.DataFrame.from_dict(result, orient='index', columns=['{}_Epochs'.format(tne)])\n",
    "    res.append(df_result)\n",
    "pd.concat(res, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Activaton Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress relu\n",
      "Progress softmax\n",
      "Progress tanh\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relu</th>\n",
       "      <th>softmax</th>\n",
       "      <th>tanh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.892600</td>\n",
       "      <td>0.872600</td>\n",
       "      <td>0.887400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.956003</td>\n",
       "      <td>0.939229</td>\n",
       "      <td>0.952604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.955487</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.952418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.268104</td>\n",
       "      <td>0.533164</td>\n",
       "      <td>0.280663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>33.513008</td>\n",
       "      <td>66.645523</td>\n",
       "      <td>35.082836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.892757</td>\n",
       "      <td>0.867166</td>\n",
       "      <td>0.896764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.494607</td>\n",
       "      <td>0.501442</td>\n",
       "      <td>0.479811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.892400</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.875600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>9376.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             relu      softmax         tanh\n",
       "accuracy                 0.892600     0.872600     0.887400\n",
       "accuracy_baseline        0.500000     0.500000     0.500000\n",
       "auc                      0.956003     0.939229     0.952604\n",
       "auc_precision_recall     0.955487     0.938130     0.952418\n",
       "average_loss             0.268104     0.533164     0.280663\n",
       "label/mean               0.500000     0.500000     0.500000\n",
       "loss                    33.513008    66.645523    35.082836\n",
       "precision                0.892757     0.867166     0.896764\n",
       "prediction/mean          0.494607     0.501442     0.479811\n",
       "recall                   0.892400     0.880000     0.875600\n",
       "global_step           9376.000000  4688.000000  4688.000000"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_functions = ['relu', 'softmax', 'tanh']\n",
    "\n",
    "res = []\n",
    "for af in activation_functions:\n",
    "    print('Progress {}'.format(af))\n",
    "    result = train_and_evaluate_DNN(bert_model, hidden_units, learning_rate, dropout_rate, train_num_epochs, input_size, af, optimizer, 'accuracy')\n",
    "    df_result = pd.DataFrame.from_dict(result, orient='index', columns=['{}'.format(af)])\n",
    "    res.append(df_result)\n",
    "pd.concat(res, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longer Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress train_uncased_large\n",
      "Progress train_uncased_large_max200\n",
      "Progress train_uncased_large_max300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_uncased_large</th>\n",
       "      <th>train_uncased_large_max200</th>\n",
       "      <th>train_uncased_large_max300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.845600</td>\n",
       "      <td>0.892400</td>\n",
       "      <td>0.895996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.929463</td>\n",
       "      <td>0.957120</td>\n",
       "      <td>0.963195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.927262</td>\n",
       "      <td>0.956087</td>\n",
       "      <td>0.963974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.344465</td>\n",
       "      <td>0.268681</td>\n",
       "      <td>0.245833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>43.058144</td>\n",
       "      <td>33.585110</td>\n",
       "      <td>31.466631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.867035</td>\n",
       "      <td>0.902709</td>\n",
       "      <td>0.887667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.469592</td>\n",
       "      <td>0.484267</td>\n",
       "      <td>0.509269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.816400</td>\n",
       "      <td>0.879600</td>\n",
       "      <td>0.906738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>14064.000000</td>\n",
       "      <td>23440.000000</td>\n",
       "      <td>3840.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train_uncased_large  train_uncased_large_max200  \\\n",
       "accuracy                         0.845600                    0.892400   \n",
       "accuracy_baseline                0.500000                    0.500000   \n",
       "auc                              0.929463                    0.957120   \n",
       "auc_precision_recall             0.927262                    0.956087   \n",
       "average_loss                     0.344465                    0.268681   \n",
       "label/mean                       0.500000                    0.500000   \n",
       "loss                            43.058144                   33.585110   \n",
       "precision                        0.867035                    0.902709   \n",
       "prediction/mean                  0.469592                    0.484267   \n",
       "recall                           0.816400                    0.879600   \n",
       "global_step                  14064.000000                23440.000000   \n",
       "\n",
       "                      train_uncased_large_max300  \n",
       "accuracy                                0.895996  \n",
       "accuracy_baseline                       0.500000  \n",
       "auc                                     0.963195  \n",
       "auc_precision_recall                    0.963974  \n",
       "average_loss                            0.245833  \n",
       "label/mean                              0.500000  \n",
       "loss                                   31.466631  \n",
       "precision                               0.887667  \n",
       "prediction/mean                         0.509269  \n",
       "recall                                  0.906738  \n",
       "global_step                          3840.000000  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_models = ['train_uncased_large', 'train_uncased_large_max200', 'train_uncased_large_max300']\n",
    "\n",
    "res = []\n",
    "for bm in bert_models:\n",
    "    print('Progress {}'.format(bm))\n",
    "    result = train_and_evaluate_DNN(bm, hidden_units, learning_rate, dropout_rate, train_num_epochs, input_size, activation_function, optimizer, 'accuracy')\n",
    "    df_result = pd.DataFrame.from_dict(result, orient='index', columns=['{}'.format(bm)])\n",
    "    res.append(df_result)\n",
    "pd.concat(res, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Model Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress train_uncased_small\n",
      "Progress train_uncased_large\n",
      "Progress train_cased_small\n",
      "Progress train_cased_large\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_uncased_small</th>\n",
       "      <th>train_uncased_large</th>\n",
       "      <th>train_cased_small</th>\n",
       "      <th>train_cased_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.819800</td>\n",
       "      <td>0.851200</td>\n",
       "      <td>0.809400</td>\n",
       "      <td>0.834200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.906073</td>\n",
       "      <td>0.928734</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>0.917374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.905724</td>\n",
       "      <td>0.926632</td>\n",
       "      <td>0.891176</td>\n",
       "      <td>0.917563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.387226</td>\n",
       "      <td>0.340968</td>\n",
       "      <td>0.411950</td>\n",
       "      <td>0.364618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>48.403313</td>\n",
       "      <td>42.621048</td>\n",
       "      <td>51.493755</td>\n",
       "      <td>45.577282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.816133</td>\n",
       "      <td>0.838473</td>\n",
       "      <td>0.817659</td>\n",
       "      <td>0.826495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.506833</td>\n",
       "      <td>0.514889</td>\n",
       "      <td>0.489571</td>\n",
       "      <td>0.508394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.825600</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.796400</td>\n",
       "      <td>0.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>4688.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train_uncased_small  train_uncased_large  \\\n",
       "accuracy                         0.819800             0.851200   \n",
       "accuracy_baseline                0.500000             0.500000   \n",
       "auc                              0.906073             0.928734   \n",
       "auc_precision_recall             0.905724             0.926632   \n",
       "average_loss                     0.387226             0.340968   \n",
       "label/mean                       0.500000             0.500000   \n",
       "loss                            48.403313            42.621048   \n",
       "precision                        0.816133             0.838473   \n",
       "prediction/mean                  0.506833             0.514889   \n",
       "recall                           0.825600             0.870000   \n",
       "global_step                   4688.000000          9376.000000   \n",
       "\n",
       "                      train_cased_small  train_cased_large  \n",
       "accuracy                       0.809400           0.834200  \n",
       "accuracy_baseline              0.500000           0.500000  \n",
       "auc                            0.892808           0.917374  \n",
       "auc_precision_recall           0.891176           0.917563  \n",
       "average_loss                   0.411950           0.364618  \n",
       "label/mean                     0.500000           0.500000  \n",
       "loss                          51.493755          45.577282  \n",
       "precision                      0.817659           0.826495  \n",
       "prediction/mean                0.489571           0.508394  \n",
       "recall                         0.796400           0.846000  \n",
       "global_step                 4688.000000        4688.000000  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_models = ['train_uncased_small', 'train_uncased_large', 'train_cased_small', 'train_cased_large']\n",
    "\n",
    "res = []\n",
    "for bm in bert_models:\n",
    "    print('Progress {}'.format(bm))\n",
    "    result = train_and_evaluate_DNN(bm, hidden_units, learning_rate, dropout_rate, train_num_epochs, input_size, activation_function, optimizer, 'accuracy')\n",
    "    df_result = pd.DataFrame.from_dict(result, orient='index', columns=['{}'.format(bm)])\n",
    "    res.append(df_result)\n",
    "pd.concat(res, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 0.3\n",
      "Progress 0.03\n",
      "Progress 0.003\n",
      "Progress 0.0003\n",
      "Progress 3e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.3_Learning_Rate</th>\n",
       "      <th>0.03_Learning_Rate</th>\n",
       "      <th>0.003_Learning_Rate</th>\n",
       "      <th>0.0003_Learning_Rate</th>\n",
       "      <th>3e-05_Learning_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.886800</td>\n",
       "      <td>0.888200</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.952882</td>\n",
       "      <td>0.954347</td>\n",
       "      <td>0.957370</td>\n",
       "      <td>0.945922</td>\n",
       "      <td>0.917904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.951977</td>\n",
       "      <td>0.954121</td>\n",
       "      <td>0.956430</td>\n",
       "      <td>0.945547</td>\n",
       "      <td>0.916720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.279179</td>\n",
       "      <td>0.273848</td>\n",
       "      <td>0.265801</td>\n",
       "      <td>0.300285</td>\n",
       "      <td>0.479364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>34.897385</td>\n",
       "      <td>34.230988</td>\n",
       "      <td>33.225075</td>\n",
       "      <td>37.535595</td>\n",
       "      <td>59.920483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.883122</td>\n",
       "      <td>0.886192</td>\n",
       "      <td>0.884013</td>\n",
       "      <td>0.864341</td>\n",
       "      <td>0.842788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.493668</td>\n",
       "      <td>0.506328</td>\n",
       "      <td>0.508961</td>\n",
       "      <td>0.498696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.891600</td>\n",
       "      <td>0.890800</td>\n",
       "      <td>0.902400</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>18752.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0.3_Learning_Rate  0.03_Learning_Rate  \\\n",
       "accuracy                       0.886800            0.888200   \n",
       "accuracy_baseline              0.500000            0.500000   \n",
       "auc                            0.952882            0.954347   \n",
       "auc_precision_recall           0.951977            0.954121   \n",
       "average_loss                   0.279179            0.273848   \n",
       "label/mean                     0.500000            0.500000   \n",
       "loss                          34.897385           34.230988   \n",
       "precision                      0.883122            0.886192   \n",
       "prediction/mean                0.505200            0.493668   \n",
       "recall                         0.891600            0.890800   \n",
       "global_step                 4688.000000         4688.000000   \n",
       "\n",
       "                      0.003_Learning_Rate  0.0003_Learning_Rate  \\\n",
       "accuracy                         0.892000              0.876000   \n",
       "accuracy_baseline                0.500000              0.500000   \n",
       "auc                              0.957370              0.945922   \n",
       "auc_precision_recall             0.956430              0.945547   \n",
       "average_loss                     0.265801              0.300285   \n",
       "label/mean                       0.500000              0.500000   \n",
       "loss                            33.225075             37.535595   \n",
       "precision                        0.884013              0.864341   \n",
       "prediction/mean                  0.506328              0.508961   \n",
       "recall                           0.902400              0.892000   \n",
       "global_step                  18752.000000           4688.000000   \n",
       "\n",
       "                      3e-05_Learning_Rate  \n",
       "accuracy                         0.838400  \n",
       "accuracy_baseline                0.500000  \n",
       "auc                              0.917904  \n",
       "auc_precision_recall             0.916720  \n",
       "average_loss                     0.479364  \n",
       "label/mean                       0.500000  \n",
       "loss                            59.920483  \n",
       "precision                        0.842788  \n",
       "prediction/mean                  0.498696  \n",
       "recall                           0.832000  \n",
       "global_step                   4688.000000  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates = [0.3, 0.03, 0.003, 0.0003, 0.00003]\n",
    "\n",
    "res = []\n",
    "for lr in learning_rates:\n",
    "    print('Progress {}'.format(lr))\n",
    "    result = train_and_evaluate_DNN(bert_model, hidden_units, lr, dropout_rate, train_num_epochs, input_size, activation_function, optimizer, 'accuracy')\n",
    "    df_result = pd.DataFrame.from_dict(result, orient='index', columns=['{}_Learning_Rate'.format(lr)])\n",
    "    res.append(df_result)\n",
    "pd.concat(res, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 0.1\n",
      "Progress 0.2\n",
      "Progress 0.3\n",
      "Progress 0.4\n",
      "Progress 0.5\n",
      "Progress 0.6\n",
      "Progress 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1_Learning_Rate</th>\n",
       "      <th>0.2_Learning_Rate</th>\n",
       "      <th>0.3_Learning_Rate</th>\n",
       "      <th>0.4_Learning_Rate</th>\n",
       "      <th>0.5_Learning_Rate</th>\n",
       "      <th>0.6_Learning_Rate</th>\n",
       "      <th>0.7_Learning_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.886800</td>\n",
       "      <td>0.887600</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.888400</td>\n",
       "      <td>0.881600</td>\n",
       "      <td>0.885200</td>\n",
       "      <td>0.886000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.953693</td>\n",
       "      <td>0.953537</td>\n",
       "      <td>0.951620</td>\n",
       "      <td>0.954516</td>\n",
       "      <td>0.951750</td>\n",
       "      <td>0.952222</td>\n",
       "      <td>0.953714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.953191</td>\n",
       "      <td>0.952816</td>\n",
       "      <td>0.951542</td>\n",
       "      <td>0.954186</td>\n",
       "      <td>0.951530</td>\n",
       "      <td>0.952976</td>\n",
       "      <td>0.953920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.282856</td>\n",
       "      <td>0.280517</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.277291</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>0.285201</td>\n",
       "      <td>0.281847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>35.357048</td>\n",
       "      <td>35.064629</td>\n",
       "      <td>36.787552</td>\n",
       "      <td>34.661400</td>\n",
       "      <td>35.823338</td>\n",
       "      <td>35.650112</td>\n",
       "      <td>35.230846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.869648</td>\n",
       "      <td>0.874131</td>\n",
       "      <td>0.918314</td>\n",
       "      <td>0.882585</td>\n",
       "      <td>0.887175</td>\n",
       "      <td>0.900916</td>\n",
       "      <td>0.867199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.515409</td>\n",
       "      <td>0.523047</td>\n",
       "      <td>0.462405</td>\n",
       "      <td>0.504710</td>\n",
       "      <td>0.484720</td>\n",
       "      <td>0.489444</td>\n",
       "      <td>0.525452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.905600</td>\n",
       "      <td>0.836400</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.874400</td>\n",
       "      <td>0.865600</td>\n",
       "      <td>0.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0.1_Learning_Rate  0.2_Learning_Rate  0.3_Learning_Rate  \\\n",
       "accuracy                       0.886800           0.887600           0.881000   \n",
       "accuracy_baseline              0.500000           0.500000           0.500000   \n",
       "auc                            0.953693           0.953537           0.951620   \n",
       "auc_precision_recall           0.953191           0.952816           0.951542   \n",
       "average_loss                   0.282856           0.280517           0.294300   \n",
       "label/mean                     0.500000           0.500000           0.500000   \n",
       "loss                          35.357048          35.064629          36.787552   \n",
       "precision                      0.869648           0.874131           0.918314   \n",
       "prediction/mean                0.515409           0.523047           0.462405   \n",
       "recall                         0.910000           0.905600           0.836400   \n",
       "global_step                 4688.000000        4688.000000        9376.000000   \n",
       "\n",
       "                      0.4_Learning_Rate  0.5_Learning_Rate  0.6_Learning_Rate  \\\n",
       "accuracy                       0.888400           0.881600           0.885200   \n",
       "accuracy_baseline              0.500000           0.500000           0.500000   \n",
       "auc                            0.954516           0.951750           0.952222   \n",
       "auc_precision_recall           0.954186           0.951530           0.952976   \n",
       "average_loss                   0.277291           0.286587           0.285201   \n",
       "label/mean                     0.500000           0.500000           0.500000   \n",
       "loss                          34.661400          35.823338          35.650112   \n",
       "precision                      0.882585           0.887175           0.900916   \n",
       "prediction/mean                0.504710           0.484720           0.489444   \n",
       "recall                         0.896000           0.874400           0.865600   \n",
       "global_step                 4688.000000        4688.000000        4688.000000   \n",
       "\n",
       "                      0.7_Learning_Rate  \n",
       "accuracy                       0.886000  \n",
       "accuracy_baseline              0.500000  \n",
       "auc                            0.953714  \n",
       "auc_precision_recall           0.953920  \n",
       "average_loss                   0.281847  \n",
       "label/mean                     0.500000  \n",
       "loss                          35.230846  \n",
       "precision                      0.867199  \n",
       "prediction/mean                0.525452  \n",
       "recall                         0.911600  \n",
       "global_step                 4688.000000  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "res = []\n",
    "for dr in dropout_rates:\n",
    "    print('Progress {}'.format(dr))\n",
    "    result = train_and_evaluate_DNN(bert_model, hidden_units, dr, dropout_rate, train_num_epochs, input_size, activation_function, optimizer, 'accuracy')\n",
    "    df_result = pd.DataFrame.from_dict(result, orient='index', columns=['{}_Dropout_Rate'.format(dr)])\n",
    "    res.append(df_result)\n",
    "pd.concat(res, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Front and Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress train_uncased_large_max200\n",
      "Progress train_uncased_large_max200_frontback\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_uncased_large_max200</th>\n",
       "      <th>train_uncased_large_max200_frontback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.892800</td>\n",
       "      <td>0.816400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.957152</td>\n",
       "      <td>0.909455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.956171</td>\n",
       "      <td>0.912010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.268967</td>\n",
       "      <td>0.376141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>33.620853</td>\n",
       "      <td>47.017639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.893115</td>\n",
       "      <td>0.814388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.497026</td>\n",
       "      <td>0.495450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.892400</td>\n",
       "      <td>0.819600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>28128.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train_uncased_large_max200  \\\n",
       "accuracy                                0.892800   \n",
       "accuracy_baseline                       0.500000   \n",
       "auc                                     0.957152   \n",
       "auc_precision_recall                    0.956171   \n",
       "average_loss                            0.268967   \n",
       "label/mean                              0.500000   \n",
       "loss                                   33.620853   \n",
       "precision                               0.893115   \n",
       "prediction/mean                         0.497026   \n",
       "recall                                  0.892400   \n",
       "global_step                         28128.000000   \n",
       "\n",
       "                      train_uncased_large_max200_frontback  \n",
       "accuracy                                          0.816400  \n",
       "accuracy_baseline                                 0.500000  \n",
       "auc                                               0.909455  \n",
       "auc_precision_recall                              0.912010  \n",
       "average_loss                                      0.376141  \n",
       "label/mean                                        0.500000  \n",
       "loss                                             47.017639  \n",
       "precision                                         0.814388  \n",
       "prediction/mean                                   0.495450  \n",
       "recall                                            0.819600  \n",
       "global_step                                    4688.000000  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_models = ['train_uncased_large_max200', 'train_uncased_large_max200_frontback']\n",
    "\n",
    "res = []\n",
    "for bm in bert_models:\n",
    "    print('Progress {}'.format(bm))\n",
    "    result = train_and_evaluate_DNN(bm, hidden_units, learning_rate, dropout_rate, train_num_epochs, input_size, activation_function, optimizer, 'accuracy')\n",
    "    df_result = pd.DataFrame.from_dict(result, orient='index', columns=['{}'.format(bm)])\n",
    "    res.append(df_result)\n",
    "pd.concat(res, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress AdaGrad\n",
      "Progress AdamW\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaGrad</th>\n",
       "      <th>AdamW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.893400</td>\n",
       "      <td>0.873200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.956967</td>\n",
       "      <td>0.946567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.955776</td>\n",
       "      <td>0.946463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.270448</td>\n",
       "      <td>0.313827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>33.805943</td>\n",
       "      <td>39.228344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.892615</td>\n",
       "      <td>0.835853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.498137</td>\n",
       "      <td>0.553442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.894400</td>\n",
       "      <td>0.928800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>32816.000000</td>\n",
       "      <td>4688.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AdaGrad        AdamW\n",
       "accuracy                  0.893400     0.873200\n",
       "accuracy_baseline         0.500000     0.500000\n",
       "auc                       0.956967     0.946567\n",
       "auc_precision_recall      0.955776     0.946463\n",
       "average_loss              0.270448     0.313827\n",
       "label/mean                0.500000     0.500000\n",
       "loss                     33.805943    39.228344\n",
       "precision                 0.892615     0.835853\n",
       "prediction/mean           0.498137     0.553442\n",
       "recall                    0.894400     0.928800\n",
       "global_step           32816.000000  4688.000000"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers = ['AdaGrad', 'AdamW']\n",
    "\n",
    "res = []\n",
    "for opt in optimizers:\n",
    "    print('Progress {}'.format(opt))\n",
    "    result = train_and_evaluate_DNN(bert_model, hidden_units, learning_rate, dropout_rate, train_num_epochs, input_size, activation_function, opt, 'accuracy')\n",
    "    df_result = pd.DataFrame.from_dict(result, orient='index', columns=['{}'.format(opt)])\n",
    "    res.append(df_result)\n",
    "pd.concat(res, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
